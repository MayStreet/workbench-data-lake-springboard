{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-Defined Tables\n",
    "\n",
    "This notebook demonstrates how to create new User-Defined Tables (UDTs) in the *User Data Lake* using `maystreet_data` API. UDTs are owned by their creator, who has permission to append data but cannot delete or modify the existing data.\n",
    "\n",
    "UDTs can be created and deleted from the *Launcher*, as illustrated in the *Workbench User Guide*; . The `maystreet_data` library also provides the ability to insert data into the tables.\n",
    "\n",
    "First, we import a few libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maystreet_data import udt\n",
    "import maystreet_data as md\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in any other data lake, tables in the User Data Lake must have a unique name, so let's define one in the cell code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = '' # enter an original name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "In order to create a table, we need to upload some existing data which will generate the schema of the table. The data can be uploaded as a Pandas DataFrame or as a Parquet file. We are going to create a table with two columns, \"a\" and \"b\". The data types will be inferred by Workbench."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1)\n",
    "\n",
    "#  Pandas DataFrame\n",
    "data_df = pd.DataFrame(dict(a=[1, 2], b=[\"x\", \"y\"]))\n",
    "# Alternatively, you can upload your CSV file:\n",
    "# data_df = pd.read_csv(\"/home/workbench/your_file.csv\")\n",
    "\n",
    "udt.create_table(name=table_name, records=data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2)\n",
    "\n",
    "# Parquet file. For the sake of simplicity, we create a Parquet file from a Pandas Dataframe.\n",
    "data_df = pd.DataFrame(dict(a=[1, 2], b=[\"x\", \"y\"]))\n",
    "parquet_file = data_df.to_parquet(\"/home/workbench/data1.parquet\")\n",
    "udt.create_table(name=table_name, records=\"/home/workbench/data1.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add more rows to the table. Note that uploading large chunks of rows at once, rather than one row at a time, drastically improves performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dict(a=[3, 4], b=[\"new data\", \"new data\"])).to_parquet(\"/home/workbench/data2.parquet\")\n",
    "udt.insert_into_table(name=table_name, records=\"/home/workbench/data2.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "We can read the table by calling `md.query()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    p_user_data_lake.\"{table_name}\"\n",
    "        \"\"\"\n",
    "\n",
    "result = md.query(md.DataSource.DATA_LAKE_USER, query)\n",
    "print(list(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also run queries across different data lakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    p_user_data_lake.\"{table_name}\"\n",
    "UNION ALL\n",
    "SELECT\n",
    "    1 AS a,\n",
    "    product AS b\n",
    "FROM\n",
    "    p_production.p_mst_data_lake.mt_trade\n",
    "WHERE\n",
    "    dt = '2024-01-03'\n",
    "    AND f = 'bats_edga'\n",
    "    AND product = 'AAPL'\n",
    "LIMIT 10\n",
    "        \"\"\"\n",
    "\n",
    "result = md.query(md.DataSource.DATA_LAKE_USER, query)\n",
    "print(list(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also rename the table if needed. If you decide to rename it, please remember to use the table's new name for further operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_table_name = '' # pick a new name for the table\n",
    "udt.rename_table(oldName=table_name, newName=new_table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once finished, let's delete the table and all its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udt.delete_table(name=table_name, confirm=\"delete_table_and_all_its_contents\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
