{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the MayStreet Data Python library - this is already provided for you inside Workbench.\n",
    "import maystreet_data\n",
    "# Import the well known Python Pandas library (https://pandas.pydata.org)\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "records_iter = maystreet_data.query(\n",
    "    maystreet_data.DataSource.DATA_LAKE,\n",
    "    f\"\"\"\n",
    "    SELECT\n",
    "        dt, guid, timestamps[1], data.headline, data.body, data.subjects\n",
    "    FROM \n",
    "        \"prod_lake.p_mst_data_lake\".mt_news\n",
    "    WHERE \n",
    "        dt='2023-05-10'\n",
    "    LIMIT 10\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "# Create a Pandas Data Frame from the iterator; an iterator will return one row at a time but we'd like\n",
    "# to see them all.\n",
    "data = pd.DataFrame(records_iter)\n",
    "\n",
    "# Display the data in the Jupyter output cell.\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the MayStreet Data Python library - this is already provided for you inside Workbench.\n",
    "import maystreet_data\n",
    "# Import the well known Python Pandas library (https://pandas.pydata.org)\n",
    "import pandas as pd\n",
    "\n",
    "# Given a ticker identifier, in this case \"COIN\", find all the news items associated with it.\n",
    "#\n",
    "# Explanation of news_plus_pids_and_rics_columns subquery:\n",
    "# Queries for all the columns in the mt_news table, and adds two columns, rics and pids.\n",
    "# These are parsed from the data column of the news table. \n",
    "# The data column is a struct containing many items, and the one we are concerned about in this query is \"subjects\".\n",
    "# The data.subjects is an array containing subject identifiers related to the news item. \n",
    "# There are several types of subjects, but the ones we are concerned with are the ones prefixed with P: and R:.\n",
    "# Subjects prefixed with P: are Refinitiv perm ids, and those prefixed with R: are Refinitive Identification Codes (RICs).\n",
    "# The columns \"rics\" and \"pids\" filter for items in data.subjects that are prefixed with R: and P: respectively,\n",
    "# and also removes the prefixes. \n",
    "# The resulting items are compared against pids and rics from the mapping tables in the WHERE clause.\n",
    "\n",
    "# Explanation of WHERE clause subqueries, going from deepest nesting and walking outwards:\n",
    "# Joins the mt_pid_to_ticker and mt_pid_to_ric mappings tables and queries it for records associated with ticker \"COIN\".\n",
    "# It casts the permid to a string (originally an int) for easier comparison to records in the mt_news table. \n",
    "# The result is ticker_mapping_subquery.\n",
    "# Then it aggregates the resulting list of rics and pids into two individual arrays (extract_rics_and_pids_from_ticker_mapping_subquery), \n",
    "# then concatenates them together (concat_pids_and_rics_to_one_array_subquery).\n",
    "# At this point the relation concat_pids_and_rics_to_one_array_subquery is a single array consisting of\n",
    "# pid and rics associated with the ticker \"COIN\".\n",
    "# This is then compared to a concatenated array of the rics and pids columns generated from news_plus_pids_and_rics_columns.\n",
    "records_iter = maystreet_data.query(\n",
    "    maystreet_data.DataSource.DATA_LAKE,\n",
    "    f\"\"\"\n",
    "    SELECT news_plus_pids_and_rics_columns.*\n",
    "    FROM (\n",
    "        SELECT *,\n",
    "        transform(filter(data.subjects, x -> regexp_like(x, '^R:*')), x -> regexp_replace(x, '(^R:)(.*)', '$2') ) AS rics,\n",
    "        transform(filter(data.subjects, (x) -> regexp_like(x, '^P:*')), (x) -> regexp_replace(x, '(^P:)(.*)', '$2')) AS pids\n",
    "        FROM mt_news\n",
    "    ) news_plus_pids_and_rics_columns\n",
    "    WHERE arrays_overlap(concat(rics, pids),  \n",
    "        (SELECT concat(ticker_rics, ticker_pids) FROM\n",
    "            (SELECT array_distinct(ARRAY_AGG(ric)) AS ticker_rics, array_distinct(ARRAY_AGG(string_pid)) AS ticker_pids\n",
    "                FROM (\n",
    "                    SELECT DISTINCT ric, CAST(mt_pid_to_ticker.permid AS VARCHAR) AS string_pid\n",
    "                    FROM mt_pid_to_ticker \n",
    "                    JOIN mt_pid_to_ric ON mt_pid_to_ticker.permid = mt_pid_to_ric.permid \n",
    "                    WHERE ticker='COIN'\n",
    "                ) ticker_mapping_subquery\n",
    "            ) extract_rics_and_pids_from_ticker_mapping_subquery\n",
    "        ) concat_pids_and_rics_to_one_array_subquery\n",
    "    ) compare_news_pids_and_rics_to_ticker_query_pids_and_rics_condition\n",
    "    LIMIT 10\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "# Create a Pandas Data Frame from the iterator; an iterator will return one row at a time but we'd like\n",
    "# to see them all.\n",
    "data = pd.DataFrame(records_iter)\n",
    "\n",
    "# Display the data in the Jupyter output cell.\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
