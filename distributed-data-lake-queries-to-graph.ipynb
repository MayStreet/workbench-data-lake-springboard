{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from maystreet_data.cluster import client\n",
    "\n",
    "# Remember! Please ensure you change the value below to the name of your cluster\n",
    "\n",
    "cluster_client = client(\"YourClusterNameHere\")\n",
    "\n",
    "\n",
    "feeds = [\"bats_edga\"]\n",
    "products = [\"IBM\", \"AAPL\", \"TSLA\", \"V\"]\n",
    "year = 2022\n",
    "month = 1\n",
    "days = [5,6,7]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import datetime\n",
    "\n",
    "from dask.dataframe import to_datetime\n",
    "import maystreet_data\n",
    "\n",
    "\n",
    "product_index_map = {product: index for index, product in enumerate(products)}\n",
    "\n",
    "\n",
    "def get_daily_price_summary_query(requested_day):\n",
    "    \"\"\"\n",
    "    Builds a query to fetch the price data broken into every minute for the products and feeds specified above.\n",
    "    \"\"\"\n",
    "\n",
    "    dt = datetime.date(year, month, requested_day).isoformat()\n",
    "\n",
    "    feeds_filter = \", \".join([f\"'{feed}'\" for feed in feeds])\n",
    "    products_filter = \", \".join([f\"'{product}'\" for product in products])\n",
    "\n",
    "    return f\"\"\"\n",
    "    WITH\n",
    "        price_and_time AS (\n",
    "            SELECT\n",
    "                product,\n",
    "                DATE_TRUNC('minute', FROM_UNIXTIME(exchangetimestamp / 1000000000)) AS dp_minute,\n",
    "                MIN(price) AS min_price,\n",
    "                MAX(price) AS max_price,\n",
    "                MIN(receipttimestamp) AS min_receipt,\n",
    "                MAX(receipttimestamp) AS max_receipt\n",
    "            FROM\n",
    "                \"prod_lake.p_mst_data_lake\".mt_trade\n",
    "            WHERE\n",
    "                dt = '{dt}'\n",
    "                AND product IN ({products_filter})\n",
    "                AND f IN ({feeds_filter})\n",
    "            GROUP BY 1, 2\n",
    "        )\n",
    "    SELECT\n",
    "        product,\n",
    "        dp_minute,\n",
    "        min_price,\n",
    "        max_price,\n",
    "        (SELECT\n",
    "            MIN(price)\n",
    "        FROM\n",
    "            \"prod_lake.p_mst_data_lake\".mt_trade\n",
    "        WHERE\n",
    "            dt = '{dt}'\n",
    "            AND product IN ({products_filter})\n",
    "            AND f IN ({feeds_filter})\n",
    "            AND product = price_and_time.product\n",
    "            AND receipttimestamp = min_receipt\n",
    "        ) AS open_price,\n",
    "        (SELECT\n",
    "            MAX(price)\n",
    "        FROM\n",
    "            \"prod_lake.p_mst_data_lake\".mt_trade\n",
    "        WHERE\n",
    "            dt = '{dt}'\n",
    "            AND product IN ({products_filter})\n",
    "            AND f IN ({feeds_filter})\n",
    "            AND product = price_and_time.product\n",
    "            AND receipttimestamp = max_receipt\n",
    "        ) close_price\n",
    "    FROM\n",
    "        price_and_time\n",
    "    ORDER BY dp_minute\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# Now we create a distributed dataframe, with one partition per query.\n",
    "# If your cluster has at least 3 workers, each partition can reside in a different worker.\n",
    "# Queries are launched by the workers concurrently, but they all run in the same Data Lake cluster.\n",
    "daily_summaries = maystreet_data.data_lake_distributed_dataframe(\n",
    "    queries=[get_daily_price_summary_query(day) for day in days]\n",
    ")\n",
    "\n",
    "# this (trivial) computation is automatically distributed in the cluster\n",
    "daily_summaries = daily_summaries.assign(\n",
    "    dp_minute=to_datetime(daily_summaries[\"dp_minute\"], unit=\"ms\"),\n",
    "    product_index=daily_summaries[\"product\"].map(product_index_map),\n",
    ")\n",
    "daily_summaries = daily_summaries.assign(\n",
    "    time_ordinal=daily_summaries[\"dp_minute\"].map(datetime.datetime.toordinal)\n",
    ")\n",
    "\n",
    "# persist all the rows in the cluster memory\n",
    "daily_summaries = cluster_client.persist(daily_summaries)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x = daily_summaries['product_index']\n",
    "y = mdates.date2num(daily_summaries['dp_minute'])\n",
    "z = daily_summaries['max_price']\n",
    "\n",
    "ax.scatter(x, y, z)\n",
    "ax.yaxis.set_major_formatter(mdates.DateFormatter('%d %H:%M'))\n",
    "\n",
    "plt.xticks(range(0, len(products)), products)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "com.lseg.llg.wb.suppress-file-browser": "true",
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
